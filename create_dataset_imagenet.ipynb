{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "from IPython.display import Image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib import tenumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transforms.Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path('F:/dataset_raw_data/ILSVRC')\n",
    "IMAGE_DIR = BASE_DIR / 'Data/CLS-LOC'\n",
    "ANNOTATION_DIR = BASE_DIR / 'Annotations/CLS-LOC'\n",
    "\n",
    "BASE_SAVE_DIR = Path('./dataset/ILSVRC_original_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'train'\n",
    "\n",
    "train_image_dir = IMAGE_DIR / data_type\n",
    "train_annotation_dir = ANNOTATION_DIR / data_type\n",
    "\n",
    "train_images = sorted(train_image_dir.glob('**/*.JPEG'))\n",
    "train_annotations = sorted(train_annotation_dir.glob('**/*.xml'))\n",
    "\n",
    "save_dir = BASE_SAVE_DIR / data_type\n",
    "save_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = []\n",
    "for data_type in ['train', 'val']:\n",
    "    train_image_dir = IMAGE_DIR / data_type\n",
    "    train_annotation_dir = ANNOTATION_DIR / data_type\n",
    "\n",
    "    train_images = sorted(train_image_dir.glob('**/*.JPEG'))\n",
    "    train_annotations = sorted(train_annotation_dir.glob('**/*.xml'))\n",
    "\n",
    "    save_dir = BASE_SAVE_DIR / data_type\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for data_no, annotation_path in tenumerate(train_annotations):\n",
    "        tree = ET.parse(annotation_path)\n",
    "        root = tree.getroot()\n",
    "        object_tree = root.find('object')\n",
    "        bbox_tree = object_tree.find('bndbox')\n",
    "\n",
    "        xmin = int(bbox_tree.find('xmin').text)\n",
    "        ymin = int(bbox_tree.find('ymin').text)\n",
    "        xmax = int(bbox_tree.find('xmax').text)\n",
    "        ymax = int(bbox_tree.find('ymax').text)\n",
    "\n",
    "        category = object_tree.find('name').text\n",
    "        if category not in category_list:\n",
    "            category_list.append(category)\n",
    "        category_id = category_list.index(category)\n",
    "\n",
    "        bbox = {\n",
    "            'xmin': xmin,\n",
    "            'ymin': ymin,\n",
    "            'width': xmax - xmin,\n",
    "            'height': ymax - ymin\n",
    "        }\n",
    "        bbox_size = bbox['width'] * bbox['height']\n",
    "\n",
    "        annotation_data = [\n",
    "            {\n",
    "                'category': category,\n",
    "                'category_id': category_id,\n",
    "                'bbox': [bbox['xmin'], bbox['ymin'], bbox['width'], bbox['height']],\n",
    "                'bbox_size': bbox_size\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        if data_type == 'train':\n",
    "            image_path = train_image_dir / f'{category}/{annotation_path.stem}.JPEG'\n",
    "        elif data_type == 'val':\n",
    "            image_path = train_image_dir / f'{annotation_path.stem}.JPEG'\n",
    "        save_image_path = save_dir / f'{str(data_no).zfill(8)}.jpg'\n",
    "        # shutil.copy(image_path, save_image_path)\n",
    "        with open(save_image_path.with_suffix('.json'), 'w') as f:\n",
    "            json.dump(annotation_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(category_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_dir = IMAGE_DIR / 'train'\n",
    "temp = sorted(train_image_dir.glob('*'))\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07057c6b11c40af9b31892b774092a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594546 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_DIR = Path('./dataset/ILSVRC_original_size')\n",
    "SAVE_DIR = Path('./dataset/ILSVRC')\n",
    "(SAVE_DIR / 'train').mkdir(exist_ok=True, parents=True)\n",
    "(SAVE_DIR / 'val').mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "TARGET_IMAGE_SIZE = 224\n",
    "\n",
    "HALF_SIZE = int(TARGET_IMAGE_SIZE / 2)\n",
    "\n",
    "image_paths = sorted(BASE_DIR.glob('**/*.jpg'))\n",
    "\n",
    "for index, image_path in tenumerate(image_paths):\n",
    "    # print(image_path)\n",
    "    annotation_path = image_path.with_suffix('.json')\n",
    "    with annotation_path.open() as f:\n",
    "        annotation_data = json.load(f)\n",
    "    xmin, ymin, width, height = annotation_data[0]['bbox']\n",
    "    # print(f'bbox info: {ymin=}, {xmin=}, {width=}, {height=}')\n",
    "\n",
    "    image = cv2.imread(str(image_path))\n",
    "    if index == 399686 or index == 577747:\n",
    "        image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "    # 画像サイズが足りていなければパディング\n",
    "    image_height, image_width, _ = image.shape\n",
    "    if image_width < TARGET_IMAGE_SIZE:\n",
    "        lack_num = TARGET_IMAGE_SIZE - image_width\n",
    "        half_lack_num = int(lack_num / 2)\n",
    "\n",
    "        image = cv2.copyMakeBorder(image, top=0, bottom=0, left=half_lack_num, right=lack_num - half_lack_num, borderType=cv2.BORDER_REPLICATE)\n",
    "        x_min += half_lack_num\n",
    "\n",
    "    if image_height < TARGET_IMAGE_SIZE:\n",
    "        lack_num = TARGET_IMAGE_SIZE - image_height\n",
    "        half_lack_num = int(lack_num / 2)\n",
    "        image = cv2.copyMakeBorder(image, top=half_lack_num, bottom=lack_num - half_lack_num, left=0, right=0, borderType=cv2.BORDER_REPLICATE)\n",
    "        ymin += half_lack_num\n",
    "\n",
    "    image_height, image_width, _ = image.shape\n",
    "    # print(f'Padding後: {image_width=}, {image_height=}')\n",
    "    # print(f'bbox info: {ymin=}, {xmin=}, {width=}, {height=}')\n",
    "    # bboxの横幅が224より大きければ、bboxの値を使用\n",
    "    if width > TARGET_IMAGE_SIZE:\n",
    "        x_min = xmin\n",
    "        x_max = xmin + width\n",
    "    # 小さい場合は、224になるように切り出し\n",
    "    else:\n",
    "        x_center = int(xmin + width / 2)\n",
    "\n",
    "        x_min = x_center - HALF_SIZE\n",
    "        x_max = x_center + HALF_SIZE\n",
    "        if x_min < 0:\n",
    "            x_min = 0\n",
    "            x_max = 224\n",
    "        elif x_max >= image_width:\n",
    "            x_max = image_width\n",
    "            x_min = x_max - 224\n",
    "\n",
    "    # print(f'{x_min=}, {x_max=}')\n",
    "\n",
    "    # bboxの縦幅が224より大きければ、bboxの値を使用\n",
    "    if height > TARGET_IMAGE_SIZE:\n",
    "        y_min = ymin\n",
    "        y_max = ymin + height\n",
    "    # 小さい場合は、224になるように切り出し\n",
    "    else:\n",
    "        y_center = int(ymin + height / 2)    \n",
    "        y_min = y_center - HALF_SIZE\n",
    "        y_max = y_center + HALF_SIZE\n",
    "        if y_min < 0:\n",
    "            y_min = 0\n",
    "            y_max = 224\n",
    "        elif y_max >= image_height:\n",
    "            y_max = image_height\n",
    "            y_min = y_max - 224\n",
    "\n",
    "    # print(f'{y_min=}, {y_max=}')\n",
    "\n",
    "    cropped_image = image[y_min: y_max, x_min: x_max]\n",
    "\n",
    "    cropped_image_height, cropped_image_width, _ = cropped_image.shape\n",
    "    # print(f'{cropped_image_height=}, {cropped_image_width=}')\n",
    "\n",
    "    if cropped_image_width != TARGET_IMAGE_SIZE or cropped_image_height != TARGET_IMAGE_SIZE:\n",
    "        if cropped_image_width >= cropped_image_height:\n",
    "            target_height = round(cropped_image_height * (TARGET_IMAGE_SIZE / cropped_image_width))\n",
    "            # print(f'{target_width=}, {cropped_image_height=}, {cropped_image_width=}')\n",
    "            cropped_image = cv2.resize(image, (TARGET_IMAGE_SIZE, target_height))\n",
    "\n",
    "            resized_height, _, _ = cropped_image.shape\n",
    "            \n",
    "            lack_num = TARGET_IMAGE_SIZE - resized_height\n",
    "            half_lack_num = int(lack_num / 2)\n",
    "\n",
    "            # print(f'{cropped_image_height=}, {cropped_image_width=}, resized: {cropped_image.shape[:2]}')\n",
    "\n",
    "            cropped_image = cv2.copyMakeBorder(cropped_image, half_lack_num, lack_num - half_lack_num, 0, 0, borderType=cv2.BORDER_REPLICATE)\n",
    "        else:\n",
    "            target_width = round(cropped_image_width * (TARGET_IMAGE_SIZE / cropped_image_height))\n",
    "            # print(f'{target_width=}, {cropped_image_height=}, {cropped_image_width=}')\n",
    "            cropped_image = cv2.resize(image, (target_width, TARGET_IMAGE_SIZE))\n",
    "\n",
    "            _, resized_width, _ = cropped_image.shape\n",
    "\n",
    "            lack_num = TARGET_IMAGE_SIZE - resized_width\n",
    "            half_lack_num = int(lack_num / 2)\n",
    "\n",
    "            # print(f'{cropped_image_height=}, {cropped_image_width=}, resized: {cropped_image.shape[:2]}')\n",
    "            # print(half_lack_num, lack_num - half_lack_num)\n",
    "\n",
    "            cropped_image = cv2.copyMakeBorder(cropped_image, 0, 0, half_lack_num, lack_num - half_lack_num, borderType=cv2.BORDER_REPLICATE)\n",
    "\n",
    "\n",
    "    save_image_path = SAVE_DIR / image_path.parent.stem / image_path.name\n",
    "    assert cropped_image.shape == (224, 224, 3), f'Missing, {cropped_image.shape}'\n",
    "\n",
    "    cv2.imwrite(str(save_image_path), cropped_image)\n",
    "\n",
    "    with save_image_path.with_suffix('.json').open('w') as f:\n",
    "        json.dump(annotation_data[0], f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594546/594546 [42:58<00:00, 230.62it/s]  \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'PIL.Image' has no attribute 'from_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     sum_img \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m image\n\u001b[0;32m      7\u001b[0m avg_img \u001b[38;5;241m=\u001b[39m sum_img \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(image_paths)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_array\u001b[49m(avg_img)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'PIL.Image' has no attribute 'from_array'"
     ]
    }
   ],
   "source": [
    "image_paths = sorted(SAVE_DIR.glob('**/*.jpg'))\n",
    "sum_img = np.zeros((224, 224, 3))\n",
    "for image_path in tqdm(image_paths):\n",
    "    image = cv2.imread(str(image_path))\n",
    "    sum_img += image\n",
    "\n",
    "avg_img = sum_img / len(image_paths)\n",
    "Image.from_array(avg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dataset/ILSVRC/average.np', avg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]],\n",
       "\n",
       "       [[2, 2, 2, 2],\n",
       "        [2, 2, 2, 2],\n",
       "        [2, 2, 2, 2],\n",
       "        [2, 2, 2, 2]],\n",
       "\n",
       "       [[3, 3, 3, 3],\n",
       "        [3, 3, 3, 3],\n",
       "        [3, 3, 3, 3],\n",
       "        [3, 3, 3, 3]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array(\n",
    "    [\n",
    "        [\n",
    "            [1, 1, 1, 1],\n",
    "            [1, 1, 1, 1],\n",
    "            [1, 1, 1, 1],\n",
    "            [1, 1, 1, 1],\n",
    "        ],\n",
    "        [\n",
    "            [2, 2, 2, 2],\n",
    "            [2, 2, 2, 2],\n",
    "            [2, 2, 2, 2],\n",
    "            [2, 2, 2, 2],\n",
    "        ],\n",
    "        [\n",
    "            [3, 3, 3, 3],\n",
    "            [3, 3, 3, 3],\n",
    "            [3, 3, 3, 3],\n",
    "            [3, 3, 3, 3],\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.]]),\n",
       " array([1., 2., 3.]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.mean(axis=2), test.mean(axis=2).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, buf = cv2.imencode(\".jpg\", cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "display(Image(data=buf.tobytes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)[ymin: ymin + height, xmin: xmin + width]\n",
    "_, buf = cv2.imencode(\".jpg\", cropped_image)\n",
    "display(Image(data=buf.tobytes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in range(100) if i % 10 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 200\n",
    "\n",
    "(200 + 112) - (200 - 112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = Path('./dataset/ILSVRC/val')\n",
    "image_paths = list(IMAGE_DIR.glob('*.jpg'))\n",
    "image_path = image_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [04:17<00:00, 193.96it/s]\n"
     ]
    }
   ],
   "source": [
    "for image_path in tqdm(image_paths):\n",
    "    image = cv2.imread(str(image_path))\n",
    "    np.save(image_path.with_suffix('.npy'), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(str(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(image_path.with_suffix('.npy'), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'npy'\n",
    "if mode == 'jpg':\n",
    "    image_path = image_paths[0]\n",
    "else:\n",
    "    image_path = image_paths[0].with_suffix('.npy')\n",
    "image_path = str(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 315 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(10000):\n",
    "    image = cv2.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
